
@article{flores_missing_2023,
	title = {Missing data in multi-omics integration: {Recent} advances through artificial intelligence},
	volume = {6},
	issn = {2624-8212},
	shorttitle = {Missing data in multi-omics integration},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2023.1098308/full},
	doi = {10.3389/frai.2023.1098308},
	abstract = {Biological systems function through complex interactions between various ‘omics (biomolecules), and a more complete understanding of these systems is only possible through an integrated, multi-omic perspective. This has presented the need for the development of integration approaches that are able to capture the complex, often non-linear, interactions that define these biological systems and are adapted to the challenges of combining the heterogenous data across ‘omic views. A principal challenge to multi-omic integration is missing data because all biomolecules are not measured in all samples. Due to either cost, instrument sensitivity, or other experimental factors, data for a biological sample may be missing for one or more ‘omic techologies. Recent methodological developments in artificial intelligence and statistical learning have greatly facilitated the analyses of multi-omics data, however many of these techniques assume access to completely observed data. A subset of these methods incorporate mechanisms for handling partially observed samples, and these methods are the focus of this review. We describe recently developed approaches, noting their primary use cases and highlighting each method's approach to handling missing data. We additionally provide an overview of the more traditional missing data workflows and their limitations; and we discuss potential avenues for further developments as well as how the missing data issue and its current solutions may generalize beyond the multi-omics context.},
	urldate = {2024-12-24},
	journal = {Frontiers in Artificial Intelligence},
	author = {Flores, Javier E. and Claborne, Daniel M. and Weller, Zachary D. and Webb-Robertson, Bobbie-Jo M. and Waters, Katrina M. and Bramer, Lisa M.},
	month = feb,
	year = {2023},
	pages = {1098308},
	file = {Full Text:/Users/jens829/Zotero/storage/FTSRZ48Q/Flores et al. - 2023 - Missing data in multi-omics integration Recent advances through artificial intelligence.pdf:application/pdf},
}

@article{picard_integration_2021,
	title = {Integration strategies of multi-omics data for machine learning analysis},
	volume = {19},
	issn = {20010370},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2001037021002683},
	doi = {10.1016/j.csbj.2021.06.030},
	language = {en},
	urldate = {2024-12-24},
	journal = {Computational and Structural Biotechnology Journal},
	author = {Picard, Milan and Scott-Boyer, Marie-Pier and Bodein, Antoine and Périn, Olivier and Droit, Arnaud},
	year = {2021},
	pages = {3735--3746},
	file = {PubMed Central Full Text PDF:/Users/jens829/Zotero/storage/UQYIV95Z/Picard et al. - 2021 - Integration strategies of multi-omics data for machine learning analysis.pdf:application/pdf},
}

@article{reel_using_2021,
	title = {Using machine learning approaches for multi-omics data analysis: {A} review},
	volume = {49},
	issn = {07349750},
	shorttitle = {Using machine learning approaches for multi-omics data analysis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0734975021000458},
	doi = {10.1016/j.biotechadv.2021.107739},
	language = {en},
	urldate = {2024-12-24},
	journal = {Biotechnology Advances},
	author = {Reel, Parminder S. and Reel, Smarti and Pearson, Ewan and Trucco, Emanuele and Jefferson, Emily},
	month = jul,
	year = {2021},
	pages = {107739},
	file = {Full Text:/Users/jens829/Zotero/storage/IL6JHAYL/Reel et al. - 2021 - Using machine learning approaches for multi-omics data analysis A review.pdf:application/pdf},
}

@incollection{kuhn_7_1997,
	title = {7. {A} {Value} for n-{Person} {Games}. {Contributions} to the {Theory} of {Games} {II} (1953) 307-317.},
	isbn = {978-1-4008-2915-6},
	url = {https://www.degruyter.com/document/doi/10.1515/9781400829156-012/html},
	urldate = {2024-12-24},
	booktitle = {Classics in {Game} {Theory}},
	publisher = {Princeton University Press},
	author = {Shapley, L.},
	editor = {Kuhn, Harold William},
	month = dec,
	year = {1997},
	doi = {10.1515/9781400829156-012},
	pages = {69--79},
}

@misc{zhang_raft_2024,
	title = {{RAFT}: {Adapting} {Language} {Model} to {Domain} {Specific} {RAG}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {{RAFT}},
	url = {https://arxiv.org/abs/2403.10131},
	doi = {10.48550/ARXIV.2403.10131},
	abstract = {Pretraining Large Language Models (LLMs) on large corpora of textual data is now a standard paradigm. When using these LLMs for many downstream applications, it is common to additionally bake in new knowledge (e.g., time-critical news, or private domain knowledge) into the pretrained model either through RAG-based-prompting, or fine-tuning. However, the optimal methodology for the model to gain such new knowledge remains an open question. In this paper, we present Retrieval Augmented FineTuning (RAFT), a training recipe that improves the model's ability to answer questions in a "open-book" in-domain settings. In RAFT, given a question, and a set of retrieved documents, we train the model to ignore those documents that don't help in answering the question, which we call, distractor documents. RAFT accomplishes this by citing verbatim the right sequence from the relevant document that would help answer the question. This coupled with RAFT's chain-of-thought-style response helps improve the model's ability to reason. In domain-specific RAG, RAFT consistently improves the model's performance across PubMed, HotpotQA, and Gorilla datasets, presenting a post-training recipe to improve pre-trained LLMs to in-domain RAG. RAFT's code and demo are open-sourced at github.com/ShishirPatil/gorilla.},
	urldate = {2024-12-24},
	publisher = {arXiv},
	author = {Zhang, Tianjun and Patil, Shishir G. and Jain, Naman and Shen, Sheng and Zaharia, Matei and Stoica, Ion and Gonzalez, Joseph E.},
	year = {2024},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences},
}

@misc{zha_alignscore_2023,
	title = {{AlignScore}: {Evaluating} {Factual} {Consistency} with a {Unified} {Alignment} {Function}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {{AlignScore}},
	url = {https://arxiv.org/abs/2305.16739},
	doi = {10.48550/ARXIV.2305.16739},
	abstract = {Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks. In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization). We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.},
	urldate = {2024-12-24},
	publisher = {arXiv},
	author = {Zha, Yuheng and Yang, Yichi and Li, Ruichen and Hu, Zhiting},
	year = {2023},
	note = {Version Number: 1},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences},
}

@misc{liu_llamaindex_2022,
	title = {{LlamaIndex}},
	url = {https://github.com/jerryjliu/llama_index},
	author = {Liu, Jerry},
	month = nov,
	year = {2022},
	doi = {10.5281/zenodo.1234},
}
